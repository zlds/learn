HDFS: 
	- 负责分布式存储数据、可以理解为一个分布式文件系统。此文件系统的主要特征是数据分散存储、一个文件存储在HDFS上时灰被分成若干个数据块、每个数据块分别存储在不同的服务器上。

	节点角色:
		- NameNode 是HDFS的管理节点、它存储了元数据(文件对应的数据块位置、文件大小、文件权限等)信息、同时负责读、写调度和存储分配。
		- DataNode 节点是真正的数据存储节点、用来存储数据。另外、在DataNode上每个数据块会根据设置的副本数据进行分级复制、保证同一个文件的每个数据块副本都不在同一个机器上。

Yarn:
	- 分布式资源管理器。支持CPU和内存两种资源管理器、。


Hive:
	- 可以将脚本和SQL语言翻译成MapReduce程序、扔给计算引擎去计算。


Pig:
	- 将Mysql



Spark:
	- 以内存换效率。相比传统的MapReduce大数据分析更高效、运行速度更快。

HBase:
	- 分布式列式存储数据库	



Pig 是一种脚本语言、使用类SQL的语法、开发者可以用Pig脚本描述要对大数据集上进行的操作、Pig经过编译后会生成MapReduce程序、然后在Hadoop上运行


Hive:
	是基于hadoop的一个数据仓库工具
    支持使用SQL语法来进行大数据计算、比如写一个select语句进行数据查询、然后hive会把sql转换为MapReduce任务进行运行
     数据修改只支持覆盖原数据和追加数据、不支持具体行的操作

Flume:
	针对大规模日志进行分布式收集、聚合和传输

Sqoop:
	专门将关系数据库的数据导入导出到Hadoop平台

Oozie:
	MapReduce工作流调度引擎

Yarn:
	资源调度
	早期的MapReduce即是一个执行引擎、又是一个资源调度框架	


spark起源:
	当时AMP实验室的马铁博士发现使用MapReduce进行机器学习计算的时候性能非常差、因为机器学习算法通常需要进行很多次的迭代计算、而"MapReduce每执行一次Map和Reduce计算都需要重启一次作业、带来大量的无所谓的消耗"、还一点是"MapReduce主要使用磁盘作为存储介质"



Flink
	- JobManager
		称为Master、用于协调分布式执行、它们用来调度task、协调检查点、协调失败时恢复等。
	- TaskManager
		也成为Worker、用于执行一个dataflow的task、数据缓冲和data stream的交换	


	- Checkpoint 主要目标是充当Flink中的恢复机制
		1.checkpoint是自动和定期的
	- Savepoint 主要目标是充当手动备份、恢复暂停作业的方法
		1.由用户手动管理(创建、删除)
		2.用着下次要处理之前已经处理过的数据的情况。
