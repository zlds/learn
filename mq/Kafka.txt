Kafka:
	是一种高吞吐量的分布式发布订阅消息系统。

 是一款开源的消息引擎系统
 消息引擎是一组规范。企业利用这组规范在不同系统之间传递语义标准的消息、实现松耦合的异步式数据传递。
 消息引擎系统要设定具体的传输协议、即我用什么方法把消息传输出去、常见的方法有2种: 点对点、发布/订阅模型
 系统A不能直接发送消息给系统B、中间还要隔一个消息引擎呢、是为了"削峰填谷"

消息传输方法:
 点对点模型: 也叫消息队列模型。如系统A发送的消息只能被系统B接收、其他任何系统都不能读取A发送的消息。同一条消息只能被下游的一个消费者消费。
 发布/订阅模型: 它有一个主题(Topic)的概念。发送方称为发布者(Publisher) 接收方称为订阅者(Subscriber)


JMS Java Message Service  支持上面这两种消息引擎模型。严格来说它并非传输协议二仅仅是一组API罢了。

削峰填谷: 指缓冲上下游瞬时突发流量、使其更平滑。保护下游系统、不被上游系统突发流量压垮、而导致链路雪崩。




优先级队列:
	队列设置最大的优先级，之后每条消息设置对应的优先级，队列根据消息优先级进行消费。
	应用场景: 
		不同业务消息推送
延迟队列:
	消息发送后，并不想让消费者立即拿到消息，而是等待特定的事件后，消费者才能进行消费。
	应用场景:	
		订单系统中订单支付30分钟内没有支付成功，那么这个订单将进行异常处理。	




Kafka的服务端由被称为Broker的服务进程构成、即一个Kakfa集群由多个Broker组成、Broker负责接收和处理客户端发送过来的请求、以及对消息进行持久化。

副本:
	 相同的数据拷贝到多台机器上。
	 副本的数量是可以配置的

	副本类型:
	 领导者副本  对外提供服务
	 追随者副本  追随领导者、不能与外界交互

	副本的工作机制: 生产者总是向领导者副本写消息;而消费者总是从领导者副本读消息。追随者副本: 它只做一件事、向领导者副本发送请求、请求领导者把最新生产的消息发给它、这样它能保存与领导者的同步。

Kafka 中的分区机制:
	是指将每个主题划分成多个分区、每个分区是一组有序的消息日志。
	主题是kafka中的一个逻辑概念，但分区是最小的存储单元，每个分区都是一个日志文件，记录已追加的方式写入其中。
	扩展生产者和消费者的负载。

	限制:
		topic下的一个分区只能被同一个consumer group下的一个consumer线程来消费。

	 Kafka 的分区编号是从0开始的、如果Topic有100个分区、那么它们的分区号就是从0到99

	 生产者向分区写入消息、每条消息在分区中的位置信息由一个叫位移(Offset)的数据来表征。分区中的位移从零开始
		不变、即一旦消息被成功写入到一个分区上、他的位移值就是固定的了。

Kafka 三层消息架构:
 第一层是主题层、每个主题可以配置M个分区、而每个分区又可以配置N个副本
 第二层是分区层、每个分区的N个副本中只能有一个充当领导者角色、对外提供服务;其他N1个副本是追随者副本、只是提供数据冗余之用	
 第三层是消息层、分区中包含若干条消息、每条消息的位移从0开始、依次递增。

Kafka Broker持久化:
 kafka使用消息日志(Log)来保存数据、一个日志就是磁盘上一个只能追加写消息的物理文件.追加写的好处是将随机IO、改为顺序IO。

 通过日志段的机制、来回收磁盘。定期删除消息以回收磁盘。在底层一个日志又近一步细分成多个日志段、消息被追加写到当前最新的日志段中、当写满了一个日志段后、会自动切分一个新的日志段、并将老的日志段封存起来。
 kafka在后台还有定时任务、会定期地检查老的日志段是否能够被删除、从而实现回收磁盘空间的目的。

消费者组:
	指多个消费者实例共同组成一个消费组、来消费一组主题。
	为什么要引入消费者组? 主要是为了提升消费者端的吞吐量。多个消费者实例同时消费、加速整个消费端的吞吐量。

重平衡:
	假设组内的某个实例挂掉了、Kafka能够自动检测到、然后把这个Failed实例之前负责的分区转移给其他活着的消费者。

	在Rebalance工程中，所有Consumer实例都会停止消费，等待Rebalanc完成。

	 大名鼎鼎、也是臭名昭著、因为由重平衡引发的消费者问题比比皆是。事实上、目前很多重平衡的Bug社区都无力解决重。



消费者位移:	 每个消费者在消费消息过程中必然需要有个字段、记录它当前消费到了分区的那个位置上。
			 它可能是随时变化的、毕竟它是消费者消费进度的指示器。
			 每个消费者都有自己的消费者位移

消息: Record。 是指Kafka处理的主要对象。

主题: Topic。 主题是承载着消息的逻辑容器、在实际使用中多用来区分具体的业务

分区: Partition。 一个有序不变的消息序列。每个主题下可以是多个分区。

消费位移: Offset。表示分区中没条消息的位置信息、是一个单调递增且不变的值

副本: Replica。kafka中同一条消息能够被拷贝到多个地方以提供数据冗余、这些地方就是所谓的副本。副本分为领导者副本和追随者副本、各自有不同的角色划分。副本是在分区层级下的、即每个分区可以配置多个副本实现高可用

生产者: Producer。向主题发布新消息的应用程序。

消费者: Consumer。从主题订阅新消息的应用程序

消费者位移: Consumer Offset。表示消费者消费进度、每个消费者都有自己的消费者位移。

消费者组: Consumer Group。多个消费者实例共同组成一个组、同时消费多个分区以实现高吞吐。

协调者: Coordinator 主要是为消费者组分配分区以及重平衡操作

重平衡: Rebalance。消费者组内某个消费者实例挂掉以后、其他消费者实例自动重新分配订阅主题分区。Rebalance是kafka消费者端实现高可用的重要手段

Kafka消息一致性:
	如一个topic分为0、1、2个分区、写入0到9条消息、按照轮询分布:
		0分区: 0、1、2、9
		1分区: 3、4、5
		2分区: 6、7、8
答: 目前Kafka的设计中多个分区的话无法保证全局的消息顺序。如果一定要实现全局的消息顺序、只能单分区。

Kafka分区数量一开始定义3个、后面增加分区、原来的分区数据会迁移吗？、分区数量可以减少吗？
答: 不会自动迁移、需要你手动迁移。分区数不可以减少


Zookeeper: 负责协调管理并保存Kafka集群的所有元数据信息、比如集群都有哪些borker在运行、创建了那些topic、每个topic都有多少个分区以及这些分区的leader副本都在那些机器上等信息。




kafka分区策略:
	1.轮询策略
	2.随机
	3.按关键字key
	4.地理位置

重要配置参数:
	 log.dirs 指定了Broker需要使用的若干个文件目录路径。
	 log.dir  表示单个路径
	 zookeeper.connect zk1:2181,zk2:2182
	 chroot 两套kafka集群、连接

	 log.retention.{hour|minutes|ms}  是控制一条消息数据被保存多长时间。从优先级上来说ms设置最高、minute次之、hour最低。
	 log.retention.bytes 是指定Broker为消息保存总的磁盘容量大小 默认1 无限制 
	 message.max.bytes 控制broker 能够接收指定最大消息 默认900多KB

	 listeners 监听端口
	 advertised.listeners  和listeners多了个advertised。Advertised的含义表示宣称的、公布的、就是说这组监听器是broker用于对外发布的。  主要是为外网访问用的。
	 host.name/port 通常不用指定

	 auto.create.topics.enable 是否允许自动创建Topic。
	 unclean.leader.election.enable 是否允许Unclean leader 选举
		 每个分区都有多个副本提供高可用、现在这些副本中只能有一个副本对外提供服务、即所谓的Leader副本。
		 那么问题来了、这些副本都有资格竞争Leader吗?显然不是、只有保存数据比较多的那些副本才有资格竞选、那些落后进度太多的副本没有资格做这件事。
		 如果设置成false、那么就坚持之前的原则、坚决不能让那些落后太多的副本竞选leader。这样做的后果是这个分区就不可用了、因为没有leader了。
		 如果为true、那么kafka允许你从那些跑得慢的副本中选择一个出来当leader。

	 auto.leader.rebalance.enable 是否允许定期进行leader选举 最后设置false

topic级别参数:
	 retention.ms 规定了该topic消息被保存的时间长。默认是7天、即topic只保存最近7天的消息。一旦设置了这个值、它会覆盖掉broker端的全局参数值。
	 retention.bytes 规定了要为该topic预留多大的磁盘空间。当前默认值是1、表示可以无限使用磁盘空间.可以用到多租户上
	 max.message.bytes 决定了kafka broker能够正常接收该topic的最大消息大小。

kafka jvm参数设置:
	 KAFKA_HEAP_OPTS 指定堆大小
	 KAFKA_JVM_PERFORMANCE_OPTS 指定GC参数

kafka生产者提交数据到broker时有几种机制可以选择、一般是ack等到一半以上follow收到消息返回成功、leader才会返回给生产者ok、这样即使leader挂掉了、但一般是子同步数据较多的follower会去选择成为leader、保证新的leader上还是有最新数据副本的。

分区策略:
	 轮询策略
		 也称Roundrobin策略、即顺序分配。比如一个主题下有3个分区、那么第一条消息被发送到分区0、第二条被发送到分区1、第三条被发送到分区2、以此类推。
	 随机策略:
		 也称Randomness策略。所谓随机就是我们随意地将消息放置到任意一个分区上。
		 先计算出该主题总的分区数、然后随机返回一个小于它的正整数。
	基于地理位置的:
		 一般只针对那些大规模的Kafka集群、特别是跨城市、跨国家甚至是跨大洲的集群。	
	按消息键保序策略:
		 Kafka允许为每条消息定义消息键 简称为key。同一个key的所有消息都进入到相同的分区里面、由于每个分区下的消息处理都是有顺序的、

压缩:
	 减少消息大小。能够节省网络传输带宽以及broker端的磁盘占用
	 生产者端和broker端
	 如果broker端指定了和producer端不同的压缩算法、会造成两侧压缩
	 kafka会将启用了那种压缩算法封装进行消息集合中。
	 让Broker重新压缩消息的2种例外情况: broker端指定了和producer端不同的压缩算法。broker端发生了消息格式转换

	总结: Producer端压缩、Broker端保持、Consumer端解压缩



无消息丢失配置:
	 producer 永远要使用带有回调通知的发送api、也就是说不要使用producer.send(msg)、而要使用producer.send(msg,callback)。使用callback回调、它能准确地告诉你消息是否真的提交成功了、一旦出现消息提交失败的情况、你就可以有针对性的进行处理。

	 设置acks = all。acks是producer的一个参数、代表了你对"已提交"消息的定义。如果设置成all、则表明所有副本Broker都要接收到消息、改消息才算是"已提交"。
	 设置retries为一个较大的值。这里的retries是同样是producer的参数、对应前面提到的producer自动重试、。当网络出现瞬时抖动时、消息发送可能会失败、此时配置了retries>0的producer能够自动重试消息发送、避免消息丢失。
	 


	 consumer 维持先消费(阅读)、再更新位移(书签)的顺序即可.
	 enable.auto.commit 最好把它设置成false、并采用手动提交位于的方式。

TCP连接:
	 一旦被设置成connections.max.idld.ms=1、tcp连接将成为永久长连接。 默认为9分钟


处理消息时的承诺:
	 最多一次: 消息可能会丢失、但绝不会被重复发送
	 至少一次: 消息不会丢失、但有可能被重复发送
	 精确一次: 消息不会丢失、也不会被重复发送
	kafka 默认提供的交付可靠性保障是第二种、即至少一次

kafka精确一次:
	 幂等性: 某些操作能够被执行多次、但每次得到的结果都是不变的。
			  kafka中通过props.put("enable.idempotence",ture)、producer自动升级成幂等性producer、其它所有的代码逻辑都不需要改变。kafka自动帮你做消息的重复去重。
			  只能保证单分区上的幂等性、即一个幂等性Producer能够保证某个主题的一个分区上不出现重复消息。其次它只能实现单会话上的幂等性、不能实现跨会话的幂等性。
	 事务: 事务型Producer能不保证消息原子性地写入到多个分区中。要么全部提交成功、要么全部写入失败。
		    开启enable.idempotence = true
		    设置producer端数transactional.id

		 Consumer端设置: isolation.level
			 read_uncommitted: 这是默认值、表明Consumer能够读取到Kafka写入的任何消息、不论事务型producer提交事务还是终止事务、其写入的消息都可以读取。
			 read_committed: 表明Consumer只会读取事务型producer成功提交写入的消息。

消费者组: 即Consumer Group
	 Consumer Group 是Kafka提供的可扩展且具有容错性的消费者机制。
	 每个分区只能由同一个消费者组内的一个consumer实例来消费。


生产者不丢消息:
	 生产者异步调用方式、有两个API、producer.send(msg)不带回调方法。producer.send(msg,callback)带回调方法。
	 使用时、带有回调方法的API、我们可以根据回调函数得知消息是否发送成功。

	消息确认机制(已提交消息的定义):
		 acks、当这个选项被设置"all"时、生产者发送的每一条消息除了发给Leader外还会发给所有的Follower、只有当所有的Follwer确认后才被认为发送成功。
		 0 代表生产者只要把消息发送出去以后就认为消息发送成功了。
		 1 代表生产者把消息发送到服务端、服务端的副本写成功以后、就返回成功。
		 -1 (all)代表服务端、将消息发给ISR列表里所有的replica都写入成功以后、才会返回成功响应给生产者。
		建议:
			1、如果你需要确保消息一条都不能丢失、那么建议不要开启消息队列的同步刷盘、而是用集群的方式来解决、可以配置当所有的Follower都接收到消息才返回成功。
			2、如果对消息的丢失有一定的容忍度、那么可以设置只发给一个Follower就可以返回成功了。
			3、我们的业务系统一般对于消息的丢失有一定的容忍度、比如说上面的红包系统为例、如果红包消息丢失、我们只要后续给没有发红包的用户补发红包就好了。

		举例: 假如有三个Broker，参数为min.insync.replicas=2(允许一个broker挂掉)，replication.factor=3，acks=all，那么producer每次发送Message时，都需要至少2个Brocker给予确认反馈。	


消费者不丢消息:
	 手动提交offset	


Broker不丢消息:
	分区副本数: replication.factor >=3
		这也是broker端的参数。其实这里想表达的是、最好将消息多保存几份、毕竟目前防止消息丢失的主要机制就是冗余。
	设置min.insync.replicas > 1
		消息至少被写入到多少个副本才算是"已提交"成功
	producer.type
		控制是不是主动flush，如果kafka写入到mmap之后立即flush然后再返回producer叫同步(sync);反之就是async
		kafka通过多分区多分本机制中已经能最大限度保证数据不丢失。



消息重复消费:
	 想要完全避免消息重复的消费是很难做到的、因为网络的抖动、机器的宕机和处理的异常都是比较难以避免的。所以、要放宽只要保证即使消费到了重复的消息、保证和消费一次的结果一样就好、也就是保证消息的"幂等".

	Kafka 保证消息最终在消息队列存储时只会存储一份.
		 它的做法是给每一个生产者一个唯一的ID、并且为生产的每一条消息赋予一个唯一ID、消息队列服务端会比对消息ID与存储的最后一条是否ID一致、如果一致认为是重复的消息、服务端会自动丢弃。
	消费者幂等:
		1、通用层、你可以在消息被生成的时候使用发号给它生成一个全局唯一的消息ID、消息被处理之后把这个ID存储在数据库中、在处理下一条消息之前从数据库里面查询这个全局ID是否被消费过、如果被消费过就放弃消费。	
		2、业务层: 
			 基于乐观锁、比如你的消息处理程序需要给一个人的账号加钱、那么你可以通过乐观的方式来解决。
			 如你给每个人的账号数据库中增加一个版本号字段、在生产消息时先查询这个账号的版本号、并且将版本号联同一起发送给消息队列。消费端在拿到消息和版本号后、在执行更新账号金额SQL时带上版本号。我们在更新数据时给数据加了乐观锁，这样在消费第一条消息时，version 值为 1，SQL 可以执行成功，并且同时把 version 值改为了 2；在执行第二条相同的消息时，由于 version 值不再是 1，所以这条 SQL 不能执行成功，也就保证了消息的幂等性。

			 乐观锁的另外一个用处:
				如果出现两条消息瞬间并发处理问题、这时事务都没有提交、所以都查不到、这时可以用版本乐观锁来解决。




消息顺序
	可以根据key关键字，将相同的key发送到同一个分区中，然后消费者消费的时候通过单线程消费.


	1)一个topic，一个partition，一个consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
	2)写N个内存queue，具有相同key的数据都到同一个内存queue; 然后对应N个线程，每个线程分消费一个内存queue即可，这样就能保证顺序性。

ReplicationFacto 表示有多少个副本
Replicas 列出所有副本的代理ID

参考地址:	https://stackoverflow.com/questions/48497872/replicationfactorvsreplicasinkafka/48498102


kafka位移:
	 什么是位移:
		就是consumer记录消费消息的位置
	 __consumer_offsets
		主要作用是保存kafka消费者的位移信息。新版本中将consumer的位移数据作为一条普通的kafka消息、提交到__consumer_offsets中。		



Kafka 为什么那么快:
	 顺序IO
		在7200转/分钟的STAT机械盘测试，随机IO的性能比顺序IO低了大概3到4个数量级。
	 零拷贝
	 	
	 批量压缩
		如json，文本数据压缩比通常能达到5到7倍 (用cpu时间去换磁盘空间或网络I/O传输量，牺牲一些cpu来减少网络I/O传输)
	
	 批量发送
		减少与服务端Broker处理请求的次数，从而提升总体的处理能力。调用send()方法时，不会立刻把消息发送出去，而是缓存起来，等待时机把缓存里的消息按按批次发送给服务端。		



Kafka 配置参数:
	

	 num.partitions=1 默认为1
	 min.insync.replicas 至少有一个副本确认收到消息了

	 enable.auto.commit 禁止客户端自动提交位移。确保消费完成以后在提交。

	kafak日志保留策略:
		1.基于时间
		 log.retention.hours = 72  日志保留时间(默认为7天)
		2.基于大小
		 log.retention.bytes = 基于大小的日志保留策略(默认1G)


	 replica.lag.time.max.ms  表示Follower副本能够落后Leder副本的最长时间间隔、当前默认值是10秒。就是说、只要一个Follower副本落后Leader副本的时间不能连续超过10秒、那么kafka就认为该follower副本与leader是同步的、即使此时Follwer副本中保存的消息明显少于Leader副本中的消息。
	
	 unclean.leader.election.enable 控制是否允许Unclean领导者选举。就是说开启Unclean领导者选举可能会造成数据丢失、但好处是、可用性提高。反之、禁止Unclean领导者选举的好处在于维护了数据的一致性、避免了消息丢失、但牺牲了高可用性



kafka清除策略类型:
	1.删除策略
		 默认的清除策略。当达到保留时间或大小限制时、将删除。
	2.压缩策略
		 对日志进行压缩。保留最新的副本。
	3.删除并压缩
		 将压缩、然后删除。

	具体配置参数:
		cleanup.policy  = delete  | compact  可以同时指定delete和compact(先压缩在删除)



ISR:
	 副本集合
	 ISR中的副本都是与leader同步的副本、相反、不在ISR中的追随副本就被认为是与Leader不同步的。
	 ISR不只是只包含追随者副本、它还包括leader副本、甚至在某些情况下、ISR只有Leader这一个副本。



Kafka 同步:
	kafka判断follower是否与leader同步的标准、不是看相差的消息数。


LEO LogEndOffset的缩写:
	 表示每个partition的log最后一条Message的位置。
HW HighWaermark的缩写
	 是指consumer能够看到的此partition的位置。	


Kafka 控制器:
	 它的主要作用是在zookeeper的帮助下管理和协调整个Kafka集群。
	 集群中的任意一台Broker都能充当控制器角色、但是、在运行过程中、只能有一个Broker成为控制器。


	kafka控制器选举:
		 Broker在启动时、会尝试去zookeeper中创建/controller节点。kafka当前选举控制器的规则是: 第一个成功创建/controller节点的Broker会被指定为控制器。

	控制器作用:
		1、主题管理: 创建、删除、增加分区
			 如执行: kafkatopics脚本时、大部分的后台工作都是控制器来完成的。
		2、分区重分配
			 kafkareassignpartitions
		3、集群成员管理: 新增Broker Broker主动关闭、Broker宕机
			 如会通过Watch机制检查Zookeeper的/brokers/ids节点下的字节点数量变更。
		4、元数据信息
			 就是向其他Broker提供数据服务。控制器上保存了最全的集群元数据信息、其他所有的Broker会定期接受控制器发来的原数据更新请求、从而更新其内存中的缓存数据.
			 如: 当前存活的broker列表、topic列表、topic副本数、分区数据等。

			和zookeeper的关系:
				 每当控制器初始化时、它都会从zookeeper上读取对应的元数据并填充到自己的缓存中。			

	控制器故障转移:
		1、zookeeper通过watch机制感知到并删除了/controller临时节点。
		2、之后、所有的存活的broker开始竞选新的控制器身份。
		3、其中一个成为controller、然后去zookeeper中读取集群元数据信息、并初始化到自己的缓存中。

判断Broker存活性:
	 是依赖zookeeper的临时节点。每个Broker启动后会在/brokers/ids下创建一个临时znode、当broker宕机或主动关闭后、该broker与zookeeper的会话结束、这个zoode会被自动删除。			

Kafka 线程池:
	1、请求首先给Reactor。
	2、Acceptor线程会将请求分发到后面的网络线程池。
	3、当网络线程拿到请求后、它不是自己处理、而是将请求放入到一个共享请求队列中。
	4、Broker端还有个IO线程池、负责从队列中取出请求、执行真正的处理。如果是PRODUCE生产请求、则将消息写入到底层的磁盘日志中。如果是FETCH请求、则从磁盘页缓存中读取消息。


	 网络线程: 拿到请求后、它不是自己处理、而是将请求放到一个共享请求队列中。 num.network.threads 默认值是3
	 IO线程池中的线程才是执行请求逻辑的线程。num.io.threads 默认值8


kafka高水位作用:
	1、定义消息可见性、即用来表示分区下的那些消息是可以被消费者消费的。
	2、帮助kafka完成副本同步。


	已提交和未提交:
		1.在分区高水位以下的消息被认为是已提交消息。
		2.反之就是未提交。

	消费者只能消费已提交消息。在不考虑kafka情况下(因为事务机制会影响消费者所能看到的消费的范围、它不只是简单依赖高水位来判断。它依靠一个名为LSO(Log Stable Offset)的位移值来判断事务型消费者的可见性)	

LEO:
	它表示副本写入下一条消费的位移值。
		 介于高水位和LEO之间的消费就属于未提交消息、同一个副本对象、其高水位值不会大于LEO值.

		 实际上、在Leader副本所在的Broker上、还保存了其他Folwer副本的LEO值。



位移:
	 分类:
		1、自动提交 
			 自动提交、就是指kafka consumer在后台默默地为你提交位移、作为用户的你完全不必操心这些事。
			 默认为: true
			 java consumer默认就是自动提交位移的。auto.commit.interval.ms默认为5秒、kafka每5秒会为你自动提交一次位移。

		2、手动提交
			 是指你要自己提交位移、kafka consumer压根不管。





kafka监控:
	线程状态:
		1、Log Compaction线程、这类线程是以kafkalogcleanerthread开头。这些线程是做日志Compaction。
		2、副本拉取消息的线程、通常以ReplicaFatcherThread开头。这类线程这些Follwer副本想Leader副本拉取消息的逻辑。如果此线程挂掉、系统会表现为对应的Follower副本不再从Leader副本拉取消息。
 
	客户端监控:
		1、kafkaproducernetworkthread开头的线程是你要实时监控的。它是负责实际消息发送的线程。一旦挂掉了、producer将无法正常工作。



消息队列问题:
	1、消息积压
		 消息突增的原因:
			1、发送慢了
			2、消息慢了
			
	2、消息过期时间、MQ丢弃消息
	3、mq放不下消息了	





重平衡:
	就是让一个消费者组下所有的消费者实例就如何消费订阅主题的所有分区达成共识的工程。



流处理平台: 流处理平台是处理无限数据集的数据处理引擎、而流处理是与批处理相对应的。
	所谓的无限数据、是指数据永远没有尽头。

流处理和批量处理区分:
	 如一瓶矿泉水、和一个水龙头、批处理是有限数据集(一瓶矿泉水)、而流处理就像水龙头一样
	 数据精确、流处理的计算结果会不断地逼近精确结果(因为流处理、每来一条消息、他就能计算一次结果、但由于它处理的大多数是无界数据、可能永远不会结束。因此在流处理中、我们很难精确描述结果何时是精确的)。而批处理提供准确的技术结果、但往往延迟很高。



kafka 命令:
	 创建kafka topic
	./bin/kafkatopics.sh bootstrapserver 33.83.100.140:9092  create replicationfactor 2 partitions 3 topic DmRoadSpeedAggregation2min

	 手动发消息
	./bin/kafkaconsoleproducer.sh brokerlist 192.168.96.100:9092 topic HCW_TEST_TOPIC 



earliest 
	当分区下有已提交的offset时，从提交的offset开始消费。无提交的offset时，从头开始消费
latest
	当分区下有提交的offset时，从提交的offset开始消费。无提交的offset时，消费新产生的该分区下的数据






Zookeeper在kafka中的作用:
	 Broker注册: 在Zookeeper上会有一个专门用来进行Broker服务器列表记录的节点
	 Topic注册: 在kafka中，同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息与broker的对应关系也都是由zookeeper在维护。
	 负载均衡: 





查看消费者消费进度
$ bin/kafkaconsumergroups.sh bootstrapserver <Kafka broker连接信息> describe group <group名称>

生产者最新的消息位移值: LOGENDOFFSET  消费者当前最新消费的位移值: CURRENTOFFSET值  LAG值(两者的差值)




消息QOS
	至多一次，消息可能丢失但是不会重复发送
	至少一次，消息不会丢失，但是可能会重复
	精确一次，每条消息肯定会被传输一次且仅一次


ActiveMQ
	
	1)支持多种语言和协议
		Java，C，C++，C#,Ruby Perl Python PHP
		AMQP MQTT OpenWire Stomp REST
	2)完全支持JMS1和J2EE1.4规范(持久化，XA消息，事务)	
	3)传输协议: TCP，SSL，NIO,UDP,



RocketMQ
	生产者如何保证不丢失消息:
		事务消息: 生产者发送一个half消息(对原始消息的封装)，该消息对消费者不可见，MQ通过ACK机制返回消息接收状态，生产者执行本地事务并返回给MQ一个状态(commit，rollback)，如果是commit的话MQ就会把消息给到下游，rollback的话就会丢弃该消息。状态如果为Unknow的话会过一段时间回查本地事务状态，默认回查15次，一直是Unknow状态的话就会丢弃此消息。

		为什么先发送一个half消息，作用就是先判断下MQ有没有问题，服务正不正常。

	MQ收到后写入硬盘如何保证不丢失
		数据存盘绕过缓存，改为同步刷盘，这一步需要修改broker的配置文件，将flushDiskType改为SYNC_FLUSH同步刷盘策略，默认是ASYNC_FLUSH异步刷盘。	

	消息写入硬盘后，硬盘坏了然后保证不丢
		RocketMQ采用主从结构，leader中的数据在多个follower中都有备份，防止单点故障导致数据丢失。

		master节点挂了之后Dledger接管
			接管MQ的commitLog
			选举从节点
			文件复制uncommitted状态多半从节点收到之后改为commited

	消费者消费 MQ 如何保证不丢失？
		如果是网络问题导致的消费失败可以进行重试机制，默认每条消息重试 16 次
		多线程异步消费失败，MQ 认为已经消费成功但是实际上对于业务逻辑来说消息是没有落地的，解决方案就是按照 mq 官方推荐的先执行本地事务再返回成功状态。
	整个 MQ 节点挂了如何保证不丢失？
		这种极端情况可以消息发送失败之后先存入本地，例如放到缓存中，另外启动一个线程扫描缓存的消息去重试发送。








生产者如何判断某条消息是否被消费
	答:
		1.直接RPC调用。
		2.通过另一个MQ的topic异步通知生产者。
	生产者会有一张消息表，记录消息的状态，根据状态进行重试。