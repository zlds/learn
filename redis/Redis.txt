安装：到官网下载（http://www.redis.io/），下载好之后解压，然后make，make install，安装完成以后拷贝文件，
       到/usr/src/redis2.8.17/src目录，拷贝rediscli(rediscli shutdown关闭redis),redisserver(redisserver redis.conf启动),
       redisbenchmark,在回到上级目录拷贝redis的配置文件，全部拷贝到/usr/local/redis/,在接着去启动redis，
启动命令: redisserver redis.conf 
  可能出现如下的2个问题，(注意防火墙端口6379)
# WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add ‘vm.overcommit_memory = 1′ to /etc/sysctl.conf and then reboot or run the command ‘sysctl vm.overcommit_memory=1′ for this to take effect.
警告：过量使用内存设置为0！在低内存环境下，后台保存可能失败。为了修正这个问题，请在/etc/sysctl.conf 添加一项 ‘vm.overcommit_memory = 1′ ，然后重启（或者运行命令’sysctl vm.overcommit_memory=1′ ）使其生效。按照提示修改就可以了。


Redis  分布式KV存储系统
支持复杂数据类型: list sortedset
特性: 单线程 高效 支持MS
过期机制: 主动过期访问时检测  被动过期后台线程随机探测


Redis 使用场景:
   可以做缓存、将一些热点不怎么变动的数据放到redis里面、可以减少db压力。
   分布式锁 原子性、多个并发保证只能处理一个
   计数器如点赞数、收藏数、分享等
   列表

优化:
   避免大量数据同时失效
   使用slowlog 优化耗时命令 (默认10毫秒)
   pipeline 多条命令合并一条发送  
   不要存过大的数据
   避免使用keys *
  

Redis数据类型:
              string:
                  字符串 一个key对应一个value
                  string是二进制安全的。意思是说string可以包含任何数据、如jpg图片、序列化的对象
                  一个字符串最多存储512M
                  如:
                     商品库存 加一减一
                     购物车  加一减一
                  INCR 时效数据 30秒失效  
              hash字典(哈希):
                  是一个string类型的key与value的映射表
                  value是一个hashmap
                  应用场景:
                      用户信息
              list(列表):
                  字符串列表、按插入顺序排序
                  可以实现链表或者一个队列、可以从头部或者尾部向list添加元素、最大长度2^321
                  应用场景:
                      关注列表、粉丝列表、一个简单的轻量级队列(生产者push、消费者pop/bpop)
              set(集合):
                  是一个无序的字符串集合
                  集合中的元素是唯一的
                  可以求交集、并集、差集
                  应用场景:
                      与list类似、不重复数据
              sorted set(有序集合):
                  集合是有序 
                  自动排序

Redis 常用命令:
   get 获取key
   set key:value 设置
   scan 
   info 查看信息
   config get xx 查看配置参数值
   config set xx 修改配置参数


pipeline 命令:
   pipeline 是多个命令合并成一个发送给服务端(队列)、这样的好处是减少网络往返时间。

  缺点:
   不保证事务
   是将命令缓存到内存、然后在一次发送、打包的命令越多、对内存消耗就越大

持久化:  
  RDB: 快照
    基于时间点进行备份
    就是将内存中的数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb
    优点:
      数据文件紧凑、适合备份
      在恢复大数据集时、速度比AOF的恢复速度要快
    缺点:
      数据丢失、因为是基于时间点来进行备份  
      如果redis因为某些原因而造成故障停机、那么服务器将丢失最近写入、丢失那些在内存中为持久化到快照中的数据
  SAVE 和 BGSAVE:
                 SAVE是一个同步保存操作、会阻塞所有客户端
                 BGSAVE是在后台异步执行、命令执行之后立即返回OK
  配置参数:
      save 900 1    表示900秒内如果至少有1个值变化、保存数据到磁盘上
      save 300 10   表示300秒内如果有10个key变化 保存到磁盘上
      save 60 10000 表示60秒之内如果有10000个key值变化、则把数据持久化到磁盘上

      stopwritesonbgsaveerror 当rdb持久化出错时、是否继续处理写请求(默认为yes、当有持久化监控时、可以设置为no)
      rdbcompression yes 是否压缩  压缩通过LZF压缩算法
      rdbchecksum yes 是否校验
      dbfilename rdb文件名称

AOF:
    记录服务器执行的所有写命令
    将所有写入命令及相关参数、以协议文本的方式写入文件并保存到磁盘(将写入的命令转换成协议文本)
    缺点:
      AOF的文件通常要比RDB大(致命的缺陷)
      在大量载入时AOF的速度可能会慢与RDB
      当server重启时、严重影响数据还原时间
  重写AOF的方式:
    rewrite:
            在主线程中重写、会阻塞工作线程、在生产环境中很少使用、处于废弃状态

    bgrewriteaof: 在后台子进程中重写、不会阻塞工作线程
            重写aof、合并重复、生成新命令
            压缩aof
            不会读取正在使用的AOF文件、而是将内存中的数据以命令的方式保存到临时文件、完成之后替换原来的文件
    AOF重写问题:
        子进程在重写aof期间、主进程还需要继续请求命令、而新的命令可能会对现有的数据库进行修改、这会让当前数据库和重写之后的数据库数据不一致。

        修正:
            为了解决数据库不一致的问题、增加了一个aof重写缓存、主进程在执行完写命令后、会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区。
            子进程完成对aof文件重写之后、它会向父进程发送一个完成信号、父进程接到改完成信号之后、会调用一个信号处理函数、该函数完成以下工作:
                将AOF重写缓存中的内容全部写入到新的aof、这个时候新的aof文件所保存的数据库状态和服务器当前的数据库状态一致。、
                对新的aof文件进行改名、原子的覆盖原有的aof文件。完成新旧两个aof文件的替换
        aof重写阻塞:
              主进程将aof buffer数据写入到新aof文件中时会阻塞工作线程、用户正常请求的延迟会变高、严重情况下会超时、主备同步也会出现问题、断开重连、重写同步等        
  配置参数:
    noappendfsynconrewrite no 当为yes时、在重写过程中、新的写命令不做fsync、而是放到缓存中去
    autoaofrewritepercentage 100 当前aof文件超过之前文件大小的2倍时、重写aof
    autoaofrewriteminsize 64mb 避免redis刚启动时、aof文件过小导致频繁重写、   

AOF 写回测试:
   always  同步写回、每个命令执行完、立马同步地将日志写回磁盘。
   everysec 每秒写回、每个写命令执行完、只是先把日志写到AOF文件的内存缓冲、每隔一秒把缓冲中的内容写入磁盘。
   no 操作系统控制的写回、每个写命令执行完、只是先把日志写到AOF文件的内存缓冲区、有操作系统决定何时将缓冲区内容写回磁盘。


复制集配置参数:
    slaveservestaledata 当从库同主机失去连接或者复制正在进行、从库有两种运行方式
      1.yes 从库会继续影响客户端的请求
      2.no 除去info和slavof命令之外的任何请求都会返回一个sync with master is progress
    slavereadonly slave是否只读
    replpingslaveperiod master给slave发送ping命令的频率、默认是10s发一个ping命令
    repltimeout 复制连接超时时间


    slowloglogslowerthan 默认值(10000微妙=10毫秒) 慢日志
    slowlogmaxlen 记录slowlog的最大长度


rediscli h 192.168.20.121  p 50121   
 
rediscli KEYS "doctor_*" | xargs rediscli DEL


rediscli h 192.168.20.120 p 50120  keys "*lizi_index_*" 查找


role 查看redis角色 master slave sentinel


Redis 内存回收策略:
 volatilelru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
 volatilettl 从已设置过期时间的数据中挑选将要过期的数据淘汰
 volatilerandom 从已设置过期时间的数据集中挑选任意数据淘汰
 allkeyslru 从数据集中挑选最近最少使用的数据淘汰
 allkeysrandom 从数据集中任意选择数据淘汰
 noenviction 禁止驱逐数据

从服务器:
		支持只读模式、并且该模式为从服务器的模式
		只读模式 slavereadonly 只读从服务器会拒绝任何写命令

定期删除策略:
            默认每100ms检查、是否有过期的key、有过期key则删除
            随机抽取一些key进行检查
惰性删除策略:
            请求key时检查key是否设置了过期时间、如果设置过期时间并过期、那么就会删除


redis使用近似LRU算法、通过对少量的key进行采样、

CONFIG GET xxx ：  如CONFIG GET m*
                   redis 配置参数查看
CONFIG SET maxmemorysamples 5 一次取样数量。redis使用近似LRU算法、通过对少量的key进行采样
noeviction 当达到内存限制时返回错误、客户端写入将会返回错误。del和其他命令异常。
allkeyslru 优先删除最近最不经常使用的key。
volatilelru 回收最近最少使用keys、但只回收设置过期的键。




Memcached 是一套分布式内存缓存系统、通常是作为db的前端cache使用
 m 指定内存大小  默认64
 p 端口         默认11211
 P 指定pid文件 
 d 以后台守护进程启动
 c 指定并发连接数 默认1024
 l 指定监听ip地址
 u 运行memcached的用户，默认不能由root用户启动，所以当前用户为root用户时、需要利用u参数来指定
 
 算法：余数算法（先求得键的整数哈希值、再除以服务器台数。根据余数来选择将键存放到哪一台服务器上、）、一致性哈希算法

https://code.google.com/p/memcachedsessionmanager/ tomcat memcached session


redis vs memcached
  redis是单线程、memcached是多进程
  redis支持数据类型丰富 string list set hash 和sorted set
  redis 支持数据的持久化、可以将内存中的数据保存在磁盘上
  redis可以实现主从复制、实现故障恢复




Redis Cluster
  无中心架构 (每个节点都可以做为整个集群的接入点)
  线性扩展
  
  故障自愈
  没有使用一致性hash、而是引入了哈希槽16384。
  每个key通过CRC16校验后对16384取模来决定放置那个槽

  数据一致性保证:
      不能保证数据的强一致性(异步复制)
      在特定条件下会丢失数据、原因有两点: 异步replication机制和network partition
      
  AP型: 
      通过分区来提供一定程度的可用性

  限制:
    最多1000个节点
    不支持多个数据库、只有数据库0、不支持select
    需要手动对集群进行分片迁移


  注意:
    节点之间使用gossip通信(节点通信成本高)，规模<1000  
    默认所有槽位可用，才提供服务
    一般会配合主从模式使用。


    不支持multikey操作:
        (即执行的命令需要在多个redis节点之间移动数据、比如set类型的并集、交集等(除非这些key属于同一个node)、即cluster不能进行跨nodes操作)
        hash tags:
          通过hash tags可以强制某些keys保存到同一个节点上、便于进行multi key操作  
        不在一个slot下面的key、是不能使用mget、mset等多键操作
        可以通过{}来定义组的概念、从而使key中{}相同的放到一个slot中

HASH_SLOT = CRC16(key) mod 16384  

Redis 集群常用命令:
 redistrib.rb create replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 创建集群(需要先启动各个节点)
 redistrib.rb addnode 127.0.0.1:7006 添加主节点
 redistrib.rb addnode slave masterid <masterid> <master ip> <slave ip>  添加从节点

 redistrib.rb reshard ip:port 重新分配slot

 cluster info  查看集群信息
 cluster nodes 查看节点状态
 cluster meet <ip> <port> 添加节点到集群
 cluster forget <node_id> 移除节点


集群方案:
        客户端分片:
            优点: 
              不依赖第三方分布式组件、逻辑可控
            缺点:
              静态分片技术、增加或者删除实例、要手动调整分片的程序
              夸系统、跨平台、需要维护不同的逻辑
              运维成本高、扩展需要手工操作
        代理方式:
             对客户端来说透明
             由代理来实现分片路由、管理后端实例、故障转移
            Twemproxy: Twitter
                无法支持平滑添加redis节点 需要用keepalived做高可用  
            Codis:
                支持平滑增加/减少redis实例、运维友好
                通过客户端做ha、如java客户端jodis、自动发现、自动规避之
        redis Cluster:
            完全去中心化、故障自动恢复

配置注意项:
    replbacklogsize 默认1M、主从同步时、复制挤压缓冲区 
    clientoutputbufferlimit:  
          是在server端实现的一个读缓冲区
          redis server在接收到客户端的请求后、把响应结果写到client buffer中、而不是直接发送给客户端、接着redis server处理其他请求、这样的异步方式、使得redis server不会应为网络原因阻塞其他请求
          所有的client请求redis数据的时候、redis要返回给client数据都会先保存在outputbuffer中、等所有数据传送完毕之后在清空outputbuffer中的数据


问答:
      redis集群解决了什么问题?
      答: 解决了线性集群扩展性、可伸缩
      在没出现redis集群前、是怎么解决的?
      答: 客户端分片、代理、一致性hash

      gossip协议实现去中心化(集群自身的实现、不是指数据)
      通过hash槽实现线性扩展




重新分片:
  ASK转向:  在分片的过程中
      * 对于槽s包含的键k来说、它在进行重新分片的过程中、即可能存在于原节点里面、也有可能存在新节点里面
      * 当客户端获取k时、它首先会访问原节点、如果找到就直接返回键k的值
      * 如果客户端没在原节点找到k、那么原节点就会向客户端返回一个ask转向、让它尝试到新节点里面进行寻找
      * 因此、如果一个客户端在访问时遇到了ASK转向、那么它可能需要访问两个节点才能找到它想要找的键
  MOVED转向:  分片完成之后
      * 在重新分片之后、原来位于槽s的键k已经从原节点迁移到了新节点
      * 如果一个没有察觉到集群槽分配情况已经发生了变化的客户端继续尝试向原节点获取槽s的键k、那么原节点就会向客户端返回一个moved转向、告知客户端、槽s已经被转移到了新节点、而得到这一信息的客户端则会重新向节点发送一个命令请求、尝试获取键k
      * 因此、如果一个客户端在访问时遇到了moved转向、那么它也可能需要访问两个节点才能找到它想要的键                        
集群元数据信息:
    slot槽的位置、


容错:
    节点失效检测、通过心跳来保持信息同步
    定时向其他节点发送ping命令、信息包含一项是节点是否被标记为PFAIL/FAIL、PFAIL表示可以已经失效、是尚未完全确认的失效状态、FAIL表示Node被集群大多数的Masters认定为失效（即大多数Master已认定为不可达，且不可达的时间已经超过配置的NODE_TIMEOUT

    集群进入FAIL状态:
        可能是slave无法升级master、或者有一部分slot不可用
        集群中大部分master都进入pfail状态
    gossip:
            包含多种消息、ping、pong、meet、fail等等
            ping 每个节点都会频繁的给其他节点发送ping、其中包含自己的状态、还有自己维护的集群元数据、互相通过ping交换元数据
            pong 返回ping和meet、包含自己的状态和其他信息、也可以用信息广播和更新

    clusternodetimeout 如果半数以上master节点与当前被检测master节点通信检测超时、就认为当前节点失效


redis 全量同步:
    master的缓冲区中没有足够的命令积压缓冲记录、或者如果slave引用了不在知道的历史记录、则会转而进行一个全量重同步

    psync:
        * 从库尝试发送psync命令到主库、而不是直接使用sync命令进行全量同步
        * 主库判断是否满足psync条件、满足就返回+CONTINUE进行增量同步、否则返回+FULLRESYNC runid offset
    判断是否允许psync有两个条件:
        条件一: psync命令携带的runid需要和主库的runid一致才可以进行增量同步、否则需要全量同步
        条件二: psync命令携带的offset是否超过缓冲区、如果超过则需要全量同步、否则进行增量同步

      psync ? 1 命令、请求主服务器进行数据的全量同步
      psync <runnid> <offset> 命令部分同步


    WAIT:
        当主服务器在返回客户端时，
    尽力而为保证数据安全: 在指定的时间内、有n个slave在线就认为写是安全、否则返回错误    
    minslavestowrite <slave 数量> 
    minslavesmaxlag <秒数>       

复制集如果工作:
    1. 每一个master都有一个replication id(是一个较大的伪随机数字符串)、和一个偏移量offset、master将复制流发送给slave时、发送多少个字节的数据、自身的偏移量就会增加多少。
    2. 当slave连接到master时、它会使用psync命令来发送它们记录的旧的master replication id和它们处理的偏移量、这样master会发送所需要的增量部分。
    3 如果是第一次同步slave找不到replication id时、会发送 psync ? 1 代表第一次全量同步
    4. 如果master的缓冲区中没有足够的命令积压缓冲记录、或者slave引用了未知的历史记录(replcation id)、则会进行一个全量同步、



开启慢日志
   CONFIG SET slowloglogslowerthan xxx  微秒 如10000 为10毫秒
   CONFIG SET slowlogmaxlen 5 保存多少条日志



Redis配置注意事项:
   内存大小
   内存清除策略
   慢查询日志
   maxclients 1024 最大连接数
   持久化

   安全设置:
     禁用某些命令 通过renamecommand config
     通过普通用户启动
     设置访问用户名密码


哨兵机制:
  节点:
    哨兵节点: 负责监控节点的运行情况
    数据节点: 即正常服务客户端请求的redis节点、没有主从之分

  哨兵:
     不提供数据存储服务。只是进行普通redis节点监控以及故障转移模块    

哨兵主要任务:
  监控、选主(选择主库)和通知。

  监控:
    是指哨兵进程在运行时、周期性地给所有的主从库发送PING命令、检查它们是否仍然在线运行、如果从没有在规定时间内响应哨兵的PING命令、哨兵就会吧它标记"下线状态"、如果主库没响应就会判定主库下线、然后开始自动切换主库的流程。
  选主:
    是指主库挂掉之后、从多个从库里、选主一个新的主库。
  通知:
    在切换完之后、执行通知任务、哨兵会把新主库的连接信息发给其他从库、让它们执行replicaof命令、和新主库建立连接、并进行数据复制。同时、会把新主库的连接信息通知给客户端、让它们把请求操作发到新主库上。     


主观下线:
   哨兵进程会使用PING命令检测它自己和主、从库的网络连接情况、用来判断实例的状态。如果哨兵发现主库或从库对PING命令的响应超时了、那么、哨兵就会把它标记为"主观下线"。



客观下线:
   就是当有N个哨兵实例时、最好要有N/2+1个实例判断主库为"主观下线"、才能最终判定主库为"客观下线"。主库是否下线不是由一个哨兵节点说了算、而是由多个哨兵节点同意、才能认为下线。  
   哨兵集群要判定主库"客观下线"、需要有一定数量的实例都认为该主库已经"主观下线"了

具体流程:
  1、ismasterdownbyaddr命令、表示自己判定主库"主观下线后"、就会给其他实例发送。接着其他哨兵会根据自己和主库的连接情况、做出Y或N的响应、Y相当于赞成、N相当于反对票
  2、当一个哨兵获得了仲裁所需的赞成票数后、就可以标记主库为"客观下线"。

leader选举:
  1.当一个哨兵获得仲裁所需要的赞成数后、就可以标记主库为"客观下线"。此时、这个哨兵就可以再给其他哨兵发送命令、表名希望由自己来执行主从切换、并让所有其他哨兵进行投票。
  最终执行主从切换的哨兵称为Leader  

  在投票过程中、任何一个想成为Leader的哨兵、要满足两个条件:  第一个、拿到半数以上的赞成票;第二、拿到的票数同时还需要大于等于哨兵配置文件中的quorum值。

 



选主过程:

  流程:
     哨兵会按照在线状态、网络状态、筛选过滤掉一部分不符合要求的从库、然后按照优先级、复制进度、ID号大小再对剩余的从库进行打分、只有得分最高的从库出现、就把它选为新主库.

  筛选 + 打分。

  筛选:
    downaftermilliseconds * 10 是我们认定主从库断连的最大连接超时时间。如果在downaftermilliseconds毫秒内、主从节点都没有通过网络联系上、就可以认为主从节点断连了、如果次数超高了10次、就说明从库网络状态不好、不适合作为新主库。

  打分:
    从库优先级、从库复制进度、从库ID号

    第一轮: 优先级最高的从库得分高
        用户可以通过slavepriority配置项、给不同的从库设置不同的优先级。可以给内存大的实例设置一个高优先级
    第二轮: 和旧主库同步进度最接近的从库得分高
        数据最新。通过master_repl_offset记录。而从库会用slave_repl_offset这个值记录当前的复制进度。
    第三轮: ID号小的从库得分高
        每个实例都会有一个ID、这个ID类似于这里的从库编号。redis规定: 在优先级和复制进度相同的情况下、ID好最小的从库得分最高、会被选举为新主库。


        

  配置参数:
     sentinel monitor mymaster 10.0.2.15  6379 2  ip为master节点地址、2是说至少经过2个sentinel同意才能认为master节点挂掉 

     downaftermilliseconds  
      超过这个时间、就会认为服务器已经断线。(默认时间30秒)
      SDOWN 主观下线(指的是单个实例)    
      ODOWN 客观下线 超过足够数量的sentinel才会下线

     sentinel parallelsyncs  1
      在故障转移时，最多可以有多少个slave同时对新的master进行同步，数字越小，完成故障转移的实际就越长。
      用于配置最多多少个从节点和主节点同步。

      在主从复制时，slave服务器在一段时间内不能处理命令请求: 如果全部slave服务器一起对新的master服务器进行同步，那么就可能造成所有slave服务器在短时间内全部不可用。


    sentinel 以每秒向主服务器发送一个PING命令
    

     PING
      +PONG 
      LOADING
      MASTERDOWN


sentinel 是一个分布式系统、sentinel之间使用gossip协议来接收服务器是否下线的信息。并使用投票协议、来决定是否执行自动故障迁移。

当一个master失效时、会在该master下的slave、选举一个新的master、当客户端服务失效的master节点时、告知客户端新master新地址



哨兵之间之间的互相发现:
   哨兵之间的互相发现是通过在主库上发布消息、如哨兵1在主库上发布消息、哨兵2在主库上订阅。

哨兵如何知道从库的IP地址?
   这是由哨兵向主库发送INFO命令来完成的。哨兵给主库发送INFO命令、主库接受到这个命令后、就会把从库列表返回给哨兵。  








主从复制不丢失数据:
  要求至少有1个slave，数据复制和同步延迟不能超过10秒，如果slave复制数据和ack延迟太长，就任务master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据为同步到slave导致的数据丢失降低的。
  minslavestowrite 1
  minslavemaxlog 10











Redis主从复制，哨兵和集群区别:
  主从复制是为了数据备份
  哨兵是为了高可用，redis主服务器挂了哨兵可以切换
  集群则是为了单实例能力有限，搞多个分散压力(将数据按一定的规则分配到多台机器)。










codis:
  优点:
     开发简单、对应用几乎透明
     性能比Twemproxy好
     有图形界面、扩容容易、运维方便

  缺点:
     代理依旧影响性能。
     组件过多、需要很多机器资源
     修改了redis代码、导致和官方功能同步、导致新功能缓慢






1.互斥性: 任意时刻，只有一个客户端能持有锁
2.不会发生死锁: 持有锁的客户端发生崩溃，能释放掉锁
3.加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。










布隆过滤器:
  可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除












setnx
  只在键key不存在的情况下，将键key的值设置为value(set if not eXists)
  若键key已经存在，则setnx命令不做任何动作。
setex
  将key的值设置为value，并设置过期时间
  如果key已经存在，则覆盖已有的值。



hdel 删除某个键值
hlen 返回key为user中存放的所有值的个数
exists("user") 是否存在key为user的记录


maxIdle
  连接池中必须保证空闲连接数，如果不够就会创建新的连接。


timeBetweenEvictionRunsMillis
  空闲连接检测周期(毫秒)。 

testOnBorrow
  每次从池中获取连接时检查连接的有效性，无效的连接会被释放。相当于在执行每条命令前发送一个PING命令，对高并发请求的大型应用的性能有影响！







lettuce 
  基于Netty框架的事件驱动的通信，支持同步和异步调用。
  线程安全，如果不是执行阻塞和事务操作，如BLPOP和MULTI/EXEC，多个线程就可以共享一个连接
  底层基于Netty，支持高级的Redis特性，比如哨兵，集群，管道，自动重新连接和Redis数据模型。

Jedis
  官方客户端，类似于JDBC，可以看做是redis命令的包装
  基于BIO，线程不安全，需要配置连接池管理连接。

  支持全面的Redis操作API。执行操作命令和我们在redis客户端操作命令一样

  缺点
   1)线程不安全（客户端实例不是线程安全，需要通过连接池来使用jedis)
   2)不支持异步
   3)同步阻塞 (使用阻塞的I/O、且其方法调用都是同步，不支持异步)

Redisson
  提供分布式相关操作服务，分布式锁，分布式集合，可通过Redis支持延迟队列等。

  缺点:
    对字符串的操作支持比较差    



redis 管道技术 pipeline
  合并操作命令批量处理，且不阻塞前序命令


lua脚本注意事项
  脚本里面不要有耗时的操作，比如大量的计算之类的一些操作











redis set操作命令
  添加
    sadd user zhangsan
    sadd user lisi

  获取所有数据
    smembers user

  检查元素是否在集合中，存在返回1，不存在返回0
    sismember user zhangsan // 返回1
    sismember user hcw // 返回(integer) 0 

  删除
    srme user zhangsan // 返回1

  获取集合数量
    SCARD key

  差集
    SDIFF l1 l2
  交集
    SINTER l1 l2
  并集
    SUNION l1 l2
    


  将差集存储到新的集合中
    SDIFFSTORE result key1 key2



布隆过滤器
  写入
  1)通过K个哈希函数计算该数据，返回K个计算出的hash值
  2)这些K个hash值映射到对应的K个二进制的数组下标
  3)将K个下标对应的二进制数据改成1
  查询
  1)通过K个哈希函数计算该数据，对应计算出的k个hash值
  2)通过hash值找到对应的二进制的数组下标
  3)判断: 如果存在一个二进制数据是0，那么该数据不存在。如果都是1，该数据存在集合中x

  优点:
    1)空间占用极小，因为本身不存储数据而是用比特位表示数据是否存在，某种程度有保密的效果。
    2)插入与查询时间复杂度均为O(k)，常数级别，k表示散列函数执行次数。
    3)散列函数之间可以相互独立，可以在应杰指令层加速计算。
  缺点:
    1)误差。(K点可能会重复)
    2)无法删除。(k点是多个元素重复使用的，假如我们将其中一个元素的k点全部置为0则直接就会影响其他元素)









定时删除
  key设置过期时间到期之后自动删除。
惰性删除
  数据到达过期时间，不做处理。等下次访问该数据时，如果未过期，返回数据；发现已过期，删除，返回不存在。
定期删除
  周期性采取随机抽取的策略，  


定期+惰性
  如果定期删除没删除key。然后你也没及时去请求key(惰性删除也没生效)。这样，redis的内存会越来越高，你们就应该采用内存淘汰机制。










1.并发情况下，
main {
  redis.get(xxxx)// 获取编号
  databases.commit;// 提交失败
}



1.先去redis获取编号，执行事务，事务执行完毕，incr。如果是多个线程并发，那编号就会重复。
2.先去redis获取编号，然后incr，最后提交事务，事务提交失败，这个时候就会出现空洞







xx业务编号，要求递增，如现在并发10个用户，其中用户-3和用户-6插入失败，这个时候怎么保证唯一递增呢，中间不允许出现空洞。

用户-1  编号001
用户-2  编号002
用户-3  编号003 失败
用户-4  编号004
用户-5  编号005
用户-6  编号006 失败
用户-7  编号007
用户-8  编号008
用户-9  编号009
用户-10  编号0010

如果是通过redis来获取编号，每次都要加锁，加锁的这一步是不是没法跳过？有没有其他好的方法？















