架构设计的真正目的:
	- 架构设计的主要目的是为了解决软件系统复杂度带来的问题。
	- 架构也是为了应对软件系统复杂度而提出的一个解决方案

	架构设计需要遵循三个主要原则: 合适原则、简单原则 演化原则


	架构师内功: 判断力、执行力、 创新力
		- 判断力: 能够准确判断系统复杂度在哪里
		- 执行力: 能够使用合适的方案解决复杂度问题
		- 创新力: 能够创造新的解决方案解决复杂度问题

		提示内功:
			- 经验: 设计过的系统越多、系统越复杂、架构师的内功也就强、不管是成功的架构、还是失败的架构、不管是采坑的经验、还是填坑的经验、都将成为架构师内功的一部分。
			- 视野: 经验和视野都是外部输入、类似于我们吃的事物、但光吃还不行、还要消化、将其变为我们自己的营养、这就是思考的作用。思考能够将经验和视野中的模式、判断、选择、技巧等提炼出来为我所有、思考也能促使我们产生新的创意和灵感。

软件复杂度:
- 高性能:
	- 单台计算机内部为了高性能带来的复杂度 
	- 多台计算机集群为了高性能带来的复杂度

- 高可用:
	- 定义: 系统无中断地执行其功能的能力、代表系统的可用性程度、是进行系统设计时的准则之一
	- 高可用增加机器目的在于冗余处理单元	

主从复制:
- 复制延迟:
	- 写操作完成后读操作发送给主库
		这种方式和业务强绑定、对业务的侵入和影响比较大、如某个新程序员不知道代码这样写、就会导致一个bug

	2、读从库失败后再读取一次主库、也就是通常说的"二次读取"。
		和业务无绑定、只需要对底层数据库访问的API进行封装即可、实现代价较小、不足之处在于如果有很多二次读取、将大大增加主机的读操作压力。
	
	3、关键业务读写操作全部指向主库、非关键业务采用读写分离

	- 分配机制:
		一般有两种方式: 程序代码封装和中间件封装

- 分库分表
	解决存储压力、将数据分散在节点上

	两大类: 分库 和 分表

	- 数据量太大、读写的性能会下降、即使有索引也会变得很大、性能同样会下降
	- 数据文件很大、数据库的备份和恢复需要耗费很长时间
	- 数据文件越大、极端情况下丢失数据的风险就越高

- 缓存: 是将可能重复使用的数据放到内存中、一次生成、多次使用、避免每次使用都去访问存储系统。
	  弥补存储系统在某些复杂业务场景下的不足。

	应用场景:
		- 读多写少
		- 需要经过复杂运算后得出的数据

	缓存穿透: 是指缓存没有发挥作用、业务系统虽然去缓存查询数据、但缓存中没有数据、业务系统需要再次去存储系统查询数据。通常有两种情况。
		1、存储数据不存在。一般情况下、如果存储系统中没有某个数据、则不会在缓存中存储相应的数据。(黑客攻击)
		2、缓存数据生成耗费大量时间或者资源。缓存的资源生成需要花费大量时间、如果业务访问时缓存失效、那么也会出现缓存没有发挥作用。

	缓存雪崩: 是指缓存失效(过期)后引起系统性能急剧下降的情况。
	
	雪崩效应的解决方法
		1、更新锁机制.
			- 对缓存更新进行加锁保护、保证只有一个线程能够进行缓存更新、未能获取更新锁的线程要么等待锁释放后重新读取缓存、要么就返回空值或者默认值。(如缓存失效、N多线程同时请求、对数据库造成压力)

		2、后台更新
			- 由后台线程来更新缓存、而不是由业务线程来更新缓存、缓存本身的有效期设置为永久、后台线程定时更新缓存。

	缓存热点: 大量请求同一份缓存数据、则缓存服务器压力也很大
		- 解决方法是: 复制多份缓存副本、将请求分散到多个缓存服务器上、减轻缓存热点导致的单台缓存服务器压力。

		- 缓存副本细节注意: 就是不同的缓存副本不要设置统一的过期时间、否则就会出现所有缓存副本同时生成同时失效的情况、从而引发缓存雪崩效应。正确的做法是设定一个过期时间范围、不同的缓存副本的过期时间是指定范围内的随机值。

	缓存穿透和缓存击穿区别:
		穿透:
			指的是缓存中无数据，数据库中也没有数据
		击穿:
			数据库中有数据，因为热点数据失效，大量请求到达db，导致db压力暴增。

			解决方法:
				- 延长热点key的过期时间或设置永不过期，如排行榜，首页等一定会有高并发的接口.
 				- 利用互斥锁保证同一时刻只有一个客户端可以查询底层数据库的这个数据。


缓存一致性:
	1.问题:
		先修改数据库、再删除缓存。如果删除缓存失败、那么导致数据库中是新数据、缓存中是旧数据、数据就出现了不一致。
	解决思路:
		先删除缓存、再修改数据库。如果数据库修改失败、那么数据库中是旧数据、缓存中是空的、那么数据不会不一致。因为读的时候缓存没有、则读数据库旧数据、然后更新到缓存中。

旁路缓存(Cache Aside)策略
	更新数据，删除缓存，在读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。

	读策略:
		1.从缓存中读取数据
		2.如果缓存命中，则从数据库中查询数据。
		3.如果缓存不命中，则从数据库中查询数据。
		4.查询到数据后，将数据写入到缓存中，并且返回给用户。
	写策略:
		1.更新数据库中的记录。
		2.删除缓存记录。	

		如果是先删除缓存，在更新db，可能会出现缓存数据不一致的问题。假设用户的年龄是20，请求A要更新用户年龄为21，所以它删除缓存中的内容，这时，另一个请求B要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为20，并且写入到缓存中，然后请求A继续更新数据库，将用户的年龄更新为21，这就造成了缓存和数据库的不一致。

	缺点:
		最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。
		解决方法:
			1.在更新数据时也更新缓存，只是在更新缓存前先加应该分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。对于写入的性能会有一些影响
			2.更新数据时也更新缓存，只是在更新缓存前先加应该较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快过去，对业务的影响也是可以接受。	


延迟双删
	1)先更新数据库同时删除缓存，等读的时候在加载到缓存中
	2)2秒后再删除一次缓存

	如果2秒之后删除失败了怎么办? 
		1)设置缓存过期时间，比如10秒或1小时
		2)将缓存删除失败记录到日志中，利用脚本提取失败记录再次删除(缓存失效期过长7*24)








- PPC 是Process Per Connection的缩写、其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求。
	问题:
		- fork代价高: 站在操作系统的角度、创建一个进程的代价是很高的、需要分配很多内核资源。父进程的内存映像复制到子进程
		- 父子进程通信复杂: 需要采用IPC之类的进程通信方案。
		- 支持的并发连接数量有限。如果进程数越来越多、如操作系统进程调度和切换频率升高、系统压力不断上升。
	perfork模式:
		就是指提前创建进程。在启动的时候就预先创建好进程、当有新的连接进来的时候、就可以省去fork进程操作。

- TPC 是Thread Per Connection的缩写、其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。
	问题: 
		相对PPC开销小了很多(解决了PPC中fork代价和进程通信复杂的问题)、但也有新的问题
		- 创建线程虽然比创建进程代价低、但不是没有代价、高并发时(例如每秒上万连接)还是有性能问题
		- 无需进程间通信、但是线程间的互斥和共享又引入了复杂度、可能一不小心就导致了死锁问题。
		- 多线程会出现互相响应的情况、某个线程出现异常时、可能导致整个进程退出(例如内存越界)

海量连接(成千上万) 海量请求: 列如抢购、双十一等
常量连接(几十上百) 海量请求: 例如中间件
海量连接常量请求: 例如门户网站
常量连接常量请求: 列如内部运营系统、管理系统

Reactor:  来了事件我通知你、你来处理
	ppc模式最主要的问题就是每个连接都要创建进程、连接结束后进程就销毁了代价比较高。为了解决这个问题、一个自然而然的想法就是资源复用。

	- Reactor模式的核心组成部分包括Reactor和处理资源池(进程或线程池)、其中Reactor负责监听和分配事件、处理资源池负责处理事件。

	- Reactor模式:
		1、单Reactor单进程/线程
		2、单Reactor多线程。
		3、多Reactor多进程/线程。

		单Reactor单进程: 只适用业务处理非常快速的场景。如使用单Reactor单进程的Redis
		- 优点就是很简单、没有进程间通信、没有进程竞争。全部都在同一个进程内完成。
		- 缺点: 只有一个进程、无法发挥多核CPU的性能;Handler在处理某个连接上的业务时、整个进程无法处理其他连接的事件、很容易导致性能瓶颈.



	- I/O多路复用两个关键点:
		1、当多条连接共用一个阻塞对象后、进程只需要在一个阻塞对象上等待、而无须再轮询所有连接、常见的实现方式有selet、epoll、queue等
		2、当某条连接有新的数据可处理时、操作系统会通知进程、进程从阻塞状态返回、开始进行业务处理。

Proactor: 
	- 来了事件我来处理、处理完了我通知你。这里的"我"就是操作系统内核、事件就是有新连接、有数据可读、有数据可写的I/事件、"你"就是我们的程序代码
	- 非阻塞同步网络模型


Reactor与Proactor 形象比喻:
	1、假如我们去饭店点餐、饭店人很多、如果我们付完钱后、站在收银台等着饭端上来我们才离开、这就是同步阻塞
	2、如果我们付完钱后给你一个号、饭好了老板会叫号、你过来取。这就是Reactor模型
	3、如果我们付完钱给你一个号、就可以坐到座位上该干啥干啥、饭好了老板会把饭端上来送给你。这就是Proactor。


I/O操作分两个阶段:
	1、等待数据准备好(读到内核缓存)
	2、将数据从内核读到用户空间(进程空间)
	一般来说1花费的时间大于2

    1上阻塞2上也阻塞的就是同步阻塞IO
    1上非阻塞2上阻塞的是同步非阻塞IO、Reactor就是这种模型
    1上非阻塞2上非阻塞就是异步非阻塞IO Proator就是这种模型


同步和异步:
	1、同步和异步说的是代码、调用就有返回是同步、反之是异步
	2、阻塞非阻塞说的是cpu、cpu要等待就是阻塞、反之非阻塞

阻塞IO和非阻塞IO
	- 阻塞IO、是指应用程序在执行IO操作后、如果没有获取响应、就好阻塞当前线程、不能执行其他任务。
	- 非阻塞IO、是指应用程序执行IO操作后、不会阻塞当前的线程、可以继续执行其他的任务。


同步和异步的区别在于"是否需要线程自己去检查或等待数据准备好"，而阻塞和非阻塞的区别在于线程在等待I/O操作完成时是否被挂起。


负载均衡分类:  常见的3种、dns负载均衡、硬件负载均衡、软件负载均衡
	DNS负载均衡:
		- 一般用来实现地理级别的均衡。例如、北京的用户访问北京的机房、南京的用户访问南京的机房。
		- dns负载均衡、本质就是dns解析同一个域名可以返回不同的IP地址。
		- dns负载均衡实现简单、成本低、但也存在粒度太粗、算法缺少等。

		优点:
		- 简单、成本低、负载均衡工作交给dns服务器处理、无须自己开发或者维护。
		- 就近访问、提升访问速度: dns解析可以根据请求ip来源、解析成距离用户最近的服务器、可以加速访问速度。

		缺点:
		- 更新不及时: DNS缓存的时间比较长、修改dns配置后、由于缓存的原因、还有用户继续访问修改前的ip、这样访问会失败。
		- 扩展性差:
		DNS负载均衡控制权在域名商那里、无法根据业务特点针对其做更多定制化功能和扩展性。
		- 分配策略比较简单:
		dns负载均衡支持的算法少、不能区分服务器的差异(不能根据系统与服务器的状态来判断负载)、也无法感知后端服务的状态。

	硬件负载:	 通常是单独的硬件设备来实现负载均衡功能。
		优点:
		- 功能强大: 全面支持各层级的负载均衡、支持全面的负载均衡算法、支持全局的负载均衡
		- 性能强大: 对比一下、软件负载均衡支持10万级并发已经很厉害了、硬件负载均衡可以支持100万以上的并发。
		- 稳定性高: 商用硬件负载均衡、经过严格测试、大规模使用、稳定性高。
		- 支持安全防护: 除了具备负载均衡功能外、还具备防火墙、防DDOS攻击等

		缺点:
		价格昂贵: 几十上百万
		扩展能力差: 硬件设备、可能根据业务进行配置
	
	软件负载均衡
		优势: 便宜		
		
CAP 理论断言任何基于网络的数据共享系统、最多只能满足一致性、可用性、分区容忍性三要素中的两个要素。

一致性(Consistency):
	- 第一版解释: 所有节点在同一时刻都能看到相同的数据
	- 第二版解释: 对某个指定的客户端来说、读操作保证能够返回最新的写操作就结果。
		强调的是client读操作能够获取最新的写结果就没有问题、因为事务在执行过程中、client是无法读取到未提交的数据、只有等事务提交后、client才能读取到事务写入的数据、而如果事务失败则回滚。

	第一版本和第二版本的主要差异表现在: 第一版从节点node的角度描述、第二版本从客户端的角度描述
	第一版的关键词是see、第二版的关键词是read

可用性(Availability)
	- 第一版解释: 每个请求都能得到成功或者失败的响应
	- 第二版解释: 非故障的节点在合理的时间内返回合理的响应(不是错误和超时的响应)


分区容忍性(Partition Tolerance)
	- 第一版解释: 出现消息丢失或者分区错误时系统能够继续运行
	- 第二版解释: 当出现网络分区后、系统能够继续"履行责任"

CAP总结: 
	- 一致性: 每次读取要么获取最近写入的数据、要么获得一个错误
	- 可用性: 每次请求都能获得一个(非错误)响应、但不保证返回的是最新写入的数据
	- 分区容忍: 尽管任意数量的消息被节点之间的网络丢失(或延迟)、系统仍然继续运行

BASE: 是指基本可用(Basically Available) 软状态(Soft State) 最终一致性(Eventual Consistency)

	- 基本可用(Basically Available): 
	分布式系统在出现故障时、允许损失部分可用性、即保证核心可用

	- 软状态(Soft State)
	允许系统存在中间状态、而该中间状态不会影响系统整体可用性。这里的中间状态就是CAP理论中的数据不一致。

	- 最终一致性(Eventual Consistency)
	系统中的所有数据副本经过一定时间后、最终能够达到一致性的状态。
	"一定时间"和数据的特性是强关联的、不同的数据能够容忍的不一致时间是不同的。
	如用户发布的最新微博、可以容忍一定时间达到一致状态。






分布式事务:
	- 在分布式系统中、每个节点只知道自己的事务是否成功、不知道其他节点的情况。因此、当一个事务要跨越多个分布式节点的时候(如下单流程、下单系统和库存系统可能就是分别部署在不同的分布式节点中)、为了保证该事物的可以满足ACID、就要引入一个协调者。

	刚性事务:
		- 遵循ACID原则、具有强一致性。比如、数据库事务
	柔性事务:
		- 其实就是根据不同的业务场景使用不同的方法实现最终一致性、也就是说我们可以根据业务的特性做部分取舍、容忍一定时间内的数据不一致。
	BASE理论:
		- 为了支持大型分布式系统、通过牺牲强一致性、保证最终一致性、来获得高可用性、是对ACID原则的弱化。	



2PC: (Two-Phase Commit Protocol)两阶段提交
	- 第一阶段:
		- 协调者向所有的参与者发送事务内容、询问是否可以执行事务提交操作、并开始等待各参与者的响应。

		- 协调者向参与者发起Prepare、即事务预处理请求。此时参与者会打开本地数据库事务、然后开始执行数据库本地事务、但是执行完后并不会立马提交数据库本地事务、而是向协调者说:"我这边可以处理了/我这边不能处理了"、如果所有的参与者返回可以处理了、那么进行第二个阶段


	-第二阶段提交阶段:
		- 各参与者节点执行事务操作、并将undo和redo信息记入事务日志中

		- 协调者向参与者、发送全局提交确认通知(global_commit)、即你们都可以进行本地事务提交了、此时参与者就会完成自身本地数据库提交、并最终将提交结果回复"ack"给协调者。

	中断事务:
		- 任何一个参与者返回了No响应、或者等待超时之后、协调者尚无法接收到所有参与者的反馈、那么就会中断事务。
	异常处理:
	- 如协调者向参与者发起prepare、当有节点反馈"我这边不能处理"Vote_abort消息、此时协调者就会向所有参与者发起事务回滚的消息"global_rollback"、参与者收到之后会回滚事务、并向协调者发送ack确认消息、协调者向调用方返回事务失败的结果

XA-两阶段:  2PC 3PC
	- 性能问题: 执行过程中间、节点处于阻塞状态。各个操作数据库的节点此时都占用着数据库资源、只有当所有节点准备完毕、事务才会提交。这样的过程会比较漫长、对性能影响比较大。
	- 协调者单点故障: 事务协调者是整个XA模型的核心、一旦事务协调者节点挂掉、会导致参与者收不到提交或者回滚的通知、从而导致参与者节点始终处于事务无法完成的中间状态。
	- 丢失消息导致数据不一致问题: 在第二阶段、如果发生局部网络问题、一部分事务参与者收到了提交消息、另一部分参与者没有收到提交消息、那么就会导致阶段数据不一致的问题

2PC: 两阶段提交
	- 是一个非常经典的强一致、中心化的原子提交协议。中心化说的是有两类节点:  中心化协调者和N个参与者

	- 第一阶段: 协调者发起prepare请求、也就是说协调者向给几点发送事务预处理请求。直白来说就是问这件事能不能处理成功、此时各节点会打开本地数据库事务、然后开始执行数据库本地事务、执行成功不会立马提交、而是向协调者报告说: "我这边可以处理了/我这边不能处理了"。如果所有的节点都向协调者都可以处理并发送commit的话、将进入第二个阶段

	- 第二阶段: 提交
		- 协调者向所有参与者发送"全局提交确认通知"、即你们可以提交了。提交完后、参与者向协调者发送ack消息。协调者就会向调用方、返回处理完成结果。


3PC: 三阶段提交
	- 3PC把2PC的准备阶段分为: 准备阶段和预处理阶段、第一个节点只是询问给资源节点是否可以执行事务、而在第二阶段、所有的节点反馈可以执行事务、才开始执行事务。


	第一点阶段 CanCommit阶段
		协调者会发送cancommit给参与者、询问参与者"你们是否可以完成本次事务"、如果参与者认为自身可以完成事务就返回"YES"、否则"NO"。 数据库层面尝试获取数据库锁

	第二阶段 PreCommit阶段
		协调者向发送所有参与者发送PreCommit、如果所有的参与者返回"yes"、那么就会进入PreCommit阶段进行事务预提交。参与者收到后开始执行事务操作、并将undo和redo信息交记录到事务日志中、事务执行完之后、就会向协调者反馈"ack"表示我已经提交了、并等待协调者的下一步指令。

	第三阶段 DoCommit阶段
		协调者发送doCommit请求、参与者节点收到后提交事务、并向协调者反馈"ack"消息、协调者收到所有参与者的ack消息后完成事务

	2PC和3PC: 3PC对于协调者和参与者都设置了超时时间、而2PC只有协调者才拥有超时机制。主要解决参与者无法与协调者通信时、长时间无法释放资源的问题。

具体使用:
- 2PC和3PC 由于阻塞、性能太差、低吞吐的特性。
	所有会使用分布式框架、分布式事务框架是建立在更上一层的	
	是应用层的事务框架、来减少数据库层面的开销。

Paxos:  消息传递的一致性算法
	- 用于保证同一个数据分片的多副本之间的数据一致性。当这些副本分布到不同的数据中心时、这个需求尤其强烈
	- paxos协议是一个解决分布式系统中、多个节点之间就某个值(提案)达成一致(决议)的通信协议。它能够处理在少数节点离线的情况下、剩余的多少节点仍然能够达成一致。即每个节点、就是参与者、也是决策者。

	- 两种角色:
		- Proposer: 提议提案的服务器
		- Acceptor: 批准提案的服务器
		
TCC: (Try-Confirm-Cancel) 又称补偿事务。其核心是想是: 针对每个操作都要注册一个与其对应的确认和补偿(撤销操作)
	- 基于服务层实现的一种二阶事务提交。		

	Try阶段: 主要是对业务系统做检测及资源预留
	Confirm阶段: 确认执行业务操作
	Cancel节点: 取消执行业务操作

	TCC事务处理流程和2PC类似、不过2PC是跨库的DB层面、而TCC本质就是一个应用层面的2PC、需要通过业务逻辑来实现。优势在于应用自己定义数据库操作的粒度、使得降低锁冲突、提高吞吐量成为可能


FMEA (Failure mode and effects analysis 故障模式与影响分析)
- 分析方法:
	- 给出初始的架构设计图
	- 假设架构中某个部件发生故障
	- 分析此故障对系统功能造成的影响
	- 根据分析结果、判断架构是否需要进行优化。

高可用存储架构:
	主备:
		优点:
		- 对于客户端来说、不需要感知备机的存在。主库出现故障后、只需要修改地址即可。
		- 对于主机和备机来说、双方只需要进行数据复制即可、无需进行状态判断和主备切换这类复杂的操作。
		缺点:
		- 备机仅仅为备份、并没有提供读写操作、造成资源浪费。
		- 故障后需要人工干预、无法自动恢复。
	主从:
		优点:
		- 备库可以承担一部分读、缓解主库压力
		- 主库故障时、读操作相关业务可以继续运行
		缺点:
		- 主从复制架构中、客户端需要感知主从、并将不同的操作发给不同的机器进行处理。复杂度比主备要高
		- 主从复制架构中、从机提供读业务、如果主从复制延迟比较大、业务会因为数据不一致出现问题。
		- 故障时需要人工干预
	双机切换:
		- 主要是解决主机故障时、自动切换到备机。也就是说在以上两种上面增加"切换功能"、即系统自动决定主机角色、并完成角色切换。


	数据分区:
		指将数据按照一定的规则进行分区、不同分区分布在不同的地理位置上、每个分区存储一部分数据、通过这种方式来规避地理级别所造成的巨大影响。

	分区复制:   解决数据分区故障、造成一部分分区数据损坏或者丢失。
		集中式:
			- 集中式备份指存在一个总的备份中心、所有的分区都将数据备份到备份中心。
			优缺点:
			- 设计简单、各分区之间并无直接联系、可以做到互不影响
			- 扩展容易、如果需要增加分区、只需要将该分区的数据复制到备份中心即可。
			- 成本较高、需要建立一个独立的备份中心
		互备式:
			互备式是指每个分区备份另外一个分区的数据
			优缺点:
			- 设计比较复杂、各个分区除了要承担业务数据存储、还需要承担备份功能、相互之间互相关联和影响。
			- 扩展麻烦
			- 成本低、直接利用已有的设备。
		独立式:
			- 设计简单、各分区互不影响
			- 扩展容易
			- 成本高			

异地多活:
	异地多活的关键点就是异地、多活、其中异地就是指物理位置上不同的地方、类似于"不要把鸡蛋放在同一个篮子里"、多活就是指不同地理位置上的系统都能够提供业务服务。

	满足两个标准:
	1、正常情况下、用户无论访问哪一个地点的业务系统、都能够得到正确的业务服务。
	2、某个地方业务异常时候、用户访问其他地方正常的业务系统、能够得到正确的业务服务。


- 可扩展:
	- 可扩展性指系统为了应对将来需求变化而提供的一种扩展能力、当有新的需求出现时、系统不需要或者仅需要少量修改就可以支持、无须整个系统重构或者重建。

	- 预测:
		- 不能每个设计点都考虑可扩展性
		- 不能完全不考虑可扩展性
		- 所有的预测都存在出错的可能性

	核心思想: 拆
	- 拆、就是将原本大一统的系统拆分成多个规模小的部分、扩展时只修改其中一部分即可、无需整个系统到处都改、通过这种方式来减少改动范围、降低改动风险。
	常见的拆分思路:
		- 面向流程拆分: 将整个业务流程拆分非几个阶段、每个阶段作为一部分
		- 面向服务拆分: 将系统提供的服务拆分、每个服务作为一部分。
		- 面向功能拆分: 将系统提供的功能拆分、每一个功能作为一部分。	

 
微服务 和 SOA区别
	- 微服务是SOA的实现方式  SOA是一种架构理念、而微服务是SOA理念的一种具体实现方法。
	- 服务粒度: SOA的服务粒度要粗一些、而微服务的服务粒度要细一些。如、对一个大小企业来说、"员工管理系统"就是一个SOA架构中的一个服务;而如果是微服务架构、则"员工管理系统"会被拆分为更多的服务。(员工信息管理、员工考勤、员工假期)
	- 服务交付 SOA对服务的交付并没有特殊要求、因为soa更多考虑的是兼容已有的系统。微服务的架构理念要求"快速交付"、相应地要求采取自动化测试、持续集成、自动化部署等敏捷开发相关的最佳实践。


	微服务的缺陷:
	- 怎么划分、就是说怎么去定义服务的边界。
	- 没有自动化支撑、无法快速交付: 如果没有相应的自动化系统进行支撑、都是靠人工去操作、那么微服务不但达不到快速交付的末目的、甚至还不如一个大而全的系统效率高。
	- 调用链太长、性能下降: 由于微服务之间都是通过http或者RPC调用、每次调用必须经过网络。
	- 调用链太长、问题定位困难  系统拆分为微服务后、一次用户请求需要多个微服务协同处理、任意微服务的故障都将导致整个业务失败。
	

拆分方法:
	- 基于业务逻辑拆分 将系统中的业务模块按照职责范围识别出来、每个单独的业务模块拆分为一个独立的服务
	- 基于可扩展拆分 将系统中的业务模型按照稳定性排序、将已经成熟和改动不大的服务拆分为稳定服务、将经常变动和迭代的服务拆分为变动服务
	- 基于稳定性 
	- 基于性能拆分 基于性能拆分和基于可靠性拆分类似、将性能要求高或者性能压力大的模块拆分出来、避免性能压力大的服务影响其他服务。


	服务拆分的难点往往在于业务边界不清晰、历史遗留系统改造难、数据一致性问题等、康威定律。
		1、只拆分有确定边界能独立的业务
		2、服务拆分本质上是数据模型的拆分、上层应用经得起折腾、底层数据模型经不起折腾。

API网关
	是外部系统服务的接口、所有的外部系统接入系统都需要通过API网关、主要包括接入鉴权(是否允许接入)、权限控制(可以访问那些功能)、传输加密、请求路由、流量控制等功能	。



	大文件存储:
		- 业务上的大数据、例如Youtube的视频、电影网站的电影
		- 海量的日志数据、例如各种访问日志、操作日志、用户轨迹日志等

	google的3篇大数据论文: Bigtable/Map-Reduce/GFS		


运维平台核心的职责分为四大块: 配置 部署 监控 应急
	- 配置: 主要是负责资源的管理。如机器管理、ip地址管理、虚拟机管理等
	- 部署: 主要负责将系统发布到线上。例如、包管理、灰度发布管理、回滚等
	- 监控: 主要负责收集系统上线运行的相关数据并进行监控、以便及时发现问题
	- 应急: 主要负责系统出故障后的处理。例如、停止程序、下线故障机器、切换IP等

运维平台的核心设计要素是"四化": 标准化 平台化 自动化 可视化

	- 标准化: 需要制定运维标准、规范配置管理。部署流程、监控指标、应急能力等。各系统按照运维标准来实现、避免不同的系统不同的处理方式。
	- 平台化: 传统的手工运维方式需要投入大量人力、效率低、容易出错、因此需要在运维标准化的基础上、将运维的相关操作都集成到运维平台中、通过运维平台来完成运维工作。
		好处:
			- 可以将运维标准化到平台中、无须运维员死记硬背运维标准
			- 运维平台提供简单方便的操作、相比之下人工操作低效率且容易出错。
			- 运维平台是可复用的、一套运维平台可以支撑几百上千个业务系统	
	- 自动化: 传统手工运维方式效率低下的一个主要原因、就是要执行大量重复的操作、运维平台可以将这些重复操作固化下来、由系统自动完成
		如:
			- 一次手工部署需要登录机器、上传包、解压包、备份旧系统、覆盖旧系统、启动新系统、过程中需要执行大量重复或者类似的操作。有了运维平台之后、只需要点击开始"部署按钮"、系统不是完成后通知部署人员即可
			- 类似的还有监控、有了运维平台之后、运维平台可以实时收集数据并进程初步分析、当发现数据异常时自动发出告警、无需运维人员盯着数据看、或者写一大堆"grep + awk + sed" 来分析日志才能发现问题。
	- 可视化: 主要目的就是为了提升数据查看效率。不用通过人工查询数据在判断。


数据平台:		数据管理  数据分析 数据应用

	- 数据管理: 包含数据采集、数据存储 数据服务和数据安全
		1、数据采集: 从业务系统收集各类数据。如、日志、用户行为、业务数据等、将这些数据传送到数据平台。
		2、数据存储: 将从业务系统采集的数据存储到数据平台、用于后续数据分析
		3、数据访问: 负责将对外提供各种协议用于读写数据。如: sql/Hive/Key-Value 等读写协议
		4、数据安全: 通常情况下数据平台都是多个业务共享的、部分业务敏感数据需要假以保护、防止被其他业务读取甚至修改、因此需要设计数据安全策略来保护数据。

	- 数据分析: 数据分析包括数据统计、数据挖掘、机器学习、深度学习


管理平台: 管理平台的核心职责就是权限管理: 这样不用每个系统去实现权限管理。
	权限管理主要分为两部分: 身份认证、权限控制、

如何选择开源项目:
	- 聚焦是否满足业务
	- 聚焦是否成熟
	- 聚焦运维能力


APP架构:
	Web App 解决了: 快速开发 和 低成本 两个复杂度问题。
		缺点: 体验比较差

	Hybrid App: 能够较好的平衡用户体验和快速开发的问题
				- 对体验要求不高的可以采用web的方式实现
				- 对体验要求高的业务采用原生App实现

	组件化 容器化:
		独立开发、独立测试、独立上线
		组件依赖、组件之间通过消息系统进行通信、通过这种方式来实现组件隔离、从而避免各个团队之间的互相依赖和影响、以提升团体开发效率和整个系统的可扩展性。

		二者区别: 在于发布方式
			- 组件化采用的是静态发布、即所有的组件各自独立开发测试、然后跟随app的某个版本一上线
			- 容器化采用的是动态发布、即容器可以动态加载组件、组件准备好了直接发布、会动态更新组件、无需等待某个版本才能上线。				

	跨平台开发:

		同一个功能和业务、Android开发一遍、IOS也开发一篇。

		Facebook: React Native
		阿里: Weex 
		google: Flutter







团队的技术实力是在做架构设计中非常重要的考虑因素

在不影响到复杂度的同时，尽量做到高性能，不能出现很明显木桶现象.



业务系统在刚开始做架构设计的时候，你很难把它给评估出来(业务的量级和瓶颈给估算出来)和设计出来。大部分的业务系统都是先开发出来上线，上线之后随着优化不断提升
		
