DevOps
	- 主要是以驱动价值交付为主、搭建企业内部的功效平台。

	1、DevOps核心是做全栈交付、提升交付价值. SRE的核心是稳定性保障、关注业务所有活动
	2、两者的共同性: 都使用软件工程解决问题。

	倾向价值交付: 提升开发效率、提升交付效率    与敏捷的价值观贴合

SRE 关键:
	- 主要需要协调多团队合作来提高稳定性
	- 体系化。SRE是一套体系化的方法。
	- 从职能分工上、SRE体系的建设绝不是单个岗位或者单个部门就能独立完成的、必然要求有高效的跨团队组织协作才可以。

	- 从体系结构出发、设置不同的职能岗位、同时还要有让不同角色有效协作的机制。

	体系配套:
		- 与开发和业务团队落实降级
		- 在开发和测试内推动混沌工程落地
		- 与开发定制可用性衡量标准
		- 与开发、测试、devops、产品团队、共同解决代码质量和需求之间的衡量问题


SRE 和 DevOps 是你中有我、我中有你、互相成就的一个过程、


运维能力一定是整个技术架构能力的体现、而不是单纯的运维的运维能力体现。

架构review、去发现单点问题。故障注入验证应用健壮性。

稳定性关键指标:
	- MTBF 平均故障时间间隔
	- MTTR 故障平均修复时间

sre 稳定性为主  保证系统运行稳定
	- 如何提升稳定性呐:
		- 提升MTBF  也就是说减少故障发生次数、如之前平均一个月发生一次、那现在是半年发生一次
		- 降低MTTR  提升故障恢复时间。 故障是不可避免的、那就提升故障处理效率、减少故障影响时间。

	把故障发生时间间隔变长、并将故障影响时间缩短、系统稳定性是不是自然就提升了呢。答案是显然的。

运维介入:
	1.在Pre-MTBF阶段: 做好架构设计、提供限流、降级、熔断。以具备快速隔离的条件。
	2.在Post-MTBF节点: 应该做到故障复盘、总结经验、找到不足、落地改进措施等。	

SLO:
	- SLO的本质就是制定一个标准、使各方对稳定性和故障率形成一个统一的认知。


系统可用性衡量:
	- 一种是时长维度 如: 超过10分钟认为是不可用
	- 第二种是请求维度 如: 非5xx的请求、占比99.5%

衡量指标: 系统请求状态码
衡量目标: 非5xx占比、也就是成功率达到95%
影响时长: 持续10分钟

几个9的因素:
	1、成本因素:
		理论上来说、肯定是9越多稳定性越好、但是相应付出的成本和代价也会更高。如更多的冗余、主备、双活、多活。
		首要考虑: ROI (回报率)
	2、业务容忍度
		- 稳定性怎么设定、很大程度上还要取决于业务上的容忍度。对于核心业务或核心应用、比如电商的交易和支付系统、我们当然是希望成功率越高越好、一般对系统稳定性要求是: 3个9到4个9。因为这些系统一旦出现问题、就好直接影响整个网站和公司的收益、这些都是钱、所以稳定性要求必然就好提高。
		- 非核心业务: 比如商品评论、商品评分、或许: 2个9也能容忍。因为短时间的评论看不到、并不会对业务收入和用户体验造成太大的影响。
	3、系统当前的稳定性状态:
		- 结合系统的实际情况、定一个合理的标准比定一个更高的标准会更主要。
		- 从系统现状入手:
			比如、如果系统可用性是低于99%、那首先第一步是不是可以做到99%、然后在争取做到99.5%。一步一步提升、定的太高、难做、而且会打击到团队的自信心和积极性。




SLI Service Level Indicator 服务等级指标
	- 其实就是我们选择那些指标来衡量我们的稳定性。
	- 就是我们要监控的指标

SLO 服务等级目标
	- 指的就是我们设定的稳定性目标、比如"几个9"这样的明白	
	- 就是SLI指标对应的目标

指标如何选择:
	1、我们要衡量谁的稳定性。也就是说先找到稳定性的主体。
	2、这个指标能够标识这个实例是否稳定吗

	如电商业务系统、优先选择与用户体验强相关或用户可以明显感知的指标




核心链路识别:
	如:  登录 ---> 搜索 ---> 详情页 ---> 购物车

	如: 商品详情页: 评价信息就不是核心应用、用户在大促购买时不会特别在意评价、而是购买。相反的SKU、优惠券这种都是核心应用、直接决定了用户最终的购买金额。

	强依赖: 核心应用之间的依赖关系
	弱依赖: 其他应用之间的依赖关系

设定SLO有哪些原则
	第一、核心应用的SLO要更严格、非核心可用放宽
	第二、强依赖之间的核心应用、SLO要一致
	第三、弱依赖中、核心应用对非核心的依赖、要有降级、熔断和限流等服务治理手段。
	第四、Error budget策略、核心应用的错误预算要共享、就是如果某个核心应用错误预算消耗完、SLO没达成、那整条链路、原则上要全部暂停操作。

On-Call 痛点
	- 往往就是系统出现问题了、不能迅速的联系对应的责任人


On-Call
	1、确保关键角色在线
		如安排: 用户、商品、交易、支付等的Owner、或Backup中至少有一个人参与On-Call轮班。
	2、组织故障应急组织
		将关键角色纳入其中、当发生故障时、第一时间在消费群通报。
	3、与云厂商联合的On-Call
			


故障复盘黄金三问:
	第一问: 故障原因有哪些?
	第二问: 我们做什么、怎么做才能确保下次不会再出现类似故障?
	第三问: 当时如果我们做了什么、可以用更短的时间恢复业务?
	
	- 通过上面的黄金三问、我们找到了故障发生的原因、接下来就是落地。要落地、就要明确到底应该由谁来承担主要的改进职责。

	- 以更开放的心态去寻找不足、而且要从自身找不足、目的就是找到更多可以改进的地方、不断从故障中学习和改进。	

故障判断原则:
	1、健壮性原则:
		每个部件自身要具备一定的治愈能力、比如主备、集群、限流、降级和重试等等。例如、在B依赖A的状态下、被依赖A出现问题、但是能够快速恢复、而依赖方B无法快速恢复、导致故障蔓延。这时、承担主要责任的是依赖方B、而不是依赖方A。
		- 在比如、强弱依赖问题: 原则上、核心应用对非核心应用的依赖必须要有降级和限流手段。

故障复盘总结:
	- 不要纠结于故障根因到底是哪个、而是把更多的注意力放在做哪些事情、可以提升故障处理的效率、缩短业务故障时长。

	- 如某个团队的a业务出了故障、找到了问题、自身业务已经修复、那么该问题其他团队的b/c/d业务也可能会遇到、那么如何推动线上的业务全部fix

团队文化:
	- 故障复盘很重要的一点就是Leader(领头羊)的作用、如果leader复盘会上只会指责、底下的人就会默默的接受挨骂、这样会打击员工积极性。所有领头羊必须有这个意识、并时刻反思改进、鼓励改进、而不是处罚错误。		




没有监控支撑:
	- 感知到故障发生的时间就要很久。
	- 监控对事故复盘有很好的作用、能完善on-call的指标
	- 监控体系解决的问题是给我们提供一个视角、更快发现或感知到问题发生。
没有On-Call机制
	处理并解决故障问题的时间也会被拉长。

	高效的响应机制。	

监控能完善oncall的指标、on-call反过来也能促进监控的发展、又是相辅相成的关系

AIOPS:
	对业务本身没价值、它是为运维服务的。所以它的价值更多的体现在运维层面。




APM:  应用性能管理
	- 主要是针对企业关键业务的IT应用性能和用户体验的监测、优化、提供企业IT应用的可靠性和质量、保证用户得到良好的服务。降低IT总拥有成本



CMDB
	- 资产系统、管理整个服务器资产
	- 配置变更
	-  所有服务支持与交付流程
	- 支持这些流程的运作、发挥配置信息的价值
	- 场景
		监控系统
		自动化系统
		发布系统


对于使用第三方服务的思考: 
	专注业务价值:
	- 对于创业公司来说、是要商业价值、而不是技术价值、丢给专业的公司来做。较少的投入、带来更大的回报。
	- 而不是去解决技术挑战

	- 面对问题、然后解决问题。而不是假想